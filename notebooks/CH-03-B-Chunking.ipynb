{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desafío 03-B-Chunking"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Descripción general\n",
    "\n",
    "En este cuaderno, repasarás los conceptos de tokens y chunking. En el cuaderno anterior (CH-03-A-Grounding), pudimos proporcionar algo de contexto adicional para fundamentar el modelo. ¿Existe un límite para la cantidad de contexto adicional que podemos proporcionar al modelo? Desafortunadamente, la respuesta es sí. Existe un límite para la cantidad de tokens permitidos en la entrada y la salida combinadas según el modelo que se esté utilizando.\n",
    "\n",
    "Entonces, ¿qué son los tokens? Los tokens son una representación de cómo los modelos de Azure OpenAI procesan el texto. Son palabras o simplemente fragmentos de caracteres. Veamos el número total de tokens en la respuesta que obtuvimos del primer cuaderno en CH-03. Hay muchas formas de calcular tokens. En este cuaderno, echaremos un vistazo a la biblioteca `token` para contar los tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Empecemos la Implementación\n",
    "\n",
    "Necesitarás importar los módulos necesarios. Las siguientes celdas son pasos clave de configuración que completaste en los desafíos anteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install --upgrade click\n",
    "! python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "import PyPDF3\n",
    "import os\n",
    "import json\n",
    "import tiktoken\n",
    "import spacy\n",
    "from openai.error import InvalidRequestError\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())\n",
    "\n",
    "from spacy.lang.en import English \n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "import langchain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configura tu entorno para acceder a tus claves de Azure OpenAI. Consulta tu recurso de Azure OpenAI en el Portal de Azure para obtener información sobre tu punto final y claves de Azure OpenAI.\n",
    "\n",
    "Por razones de seguridad, almacena tu información sensible en un archivo .env."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your OpenAI credentials\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "assert API_KEY, \"ERROR: Azure OpenAI Key is missing\"\n",
    "openai.api_key = API_KEY\n",
    "\n",
    "RESOURCE_ENDPOINT = os.getenv(\"OPENAI_API_BASE\",\"\").strip()\n",
    "assert RESOURCE_ENDPOINT, \"ERROR: Azure OpenAI Endpoint is missing\"\n",
    "assert \"openai.azure.com\" in RESOURCE_ENDPOINT.lower(), \"ERROR: Azure OpenAI Endpoint should be in the form: \\n\\n\\t<your unique endpoint identifier>.openai.azure.com\"\n",
    "openai.api_base = RESOURCE_ENDPOINT\n",
    "\n",
    "openai.api_type = os.getenv(\"OPENAI_API_TYPE\")\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\")\n",
    "model=os.getenv(\"CHAT_MODEL_NAME\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Conteo de Tokens\n",
    "\n",
    "Tiktoken utiliza una técnica llamada codificación de pares de bytes (BPE) para convertir el texto dado en tokens. Hay diferentes codificaciones disponibles para ayudar a procesar las palabras. En este cuaderno, utilizaremos el cl100k_base.\n",
    "\n",
    "#### Tarea del Estudiante #1:\n",
    "\n",
    "Cuenta el número de tokens en la respuesta final que recibimos en CH-03-A-Grounding completando la función, count_tokens, a continuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def count_tokens(string: str, encoding_name: str) -> int:\n",
    "    # Enter code here\n",
    "    return "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tarea del Estudiante #2:\n",
    "\n",
    "Ingresa el texto de la respuesta que recibiste en CH-03-A-Grounding. Ejecuta la celda a continuación para recuperar el número de tokens utilizando la función count_tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Enter text here.\"\"\"\n",
    "\n",
    "count_tokens(text, \"cl100k_base\")\n",
    "\n",
    "print(\"There are \" + str(count_tokens(text, \"cl100k_base\")) + \" tokens: \" + text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo, ahora sabemos con cuántos tokens estamos trabajando. ¿Qué sucede si queremos agregar más contexto que el que ya pusimos en la variable de texto anterior? Si pensamos en nuestro escenario de Wimbledon, necesitaremos darle al modelo más contexto para ayudarlo a entender todo lo que necesita saber sobre el torneo. Más importante aún, todo lo que necesita saber para ayudar a responder tus preguntas al escribir el informe. Digamos que queremos proporcionar más contexto al modelo con un documento PDF. ¿Podemos intentar obtener un resumen del documento PDF para ayudarnos con nuestro trabajo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tarea del Estudiante #3:\n",
    "\n",
    "En la celda siguiente, inserta la ruta del documento PDF, `CH3-data.pdf`, que se encuentra en la carpeta `/data` proporcionada. Ejecuta las tres celdas para ver la salida."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "document = open(r'Insert PDF file path', 'rb') \n",
    "doc_helper = PyPDF3.PdfFileReader(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaltext = ''\n",
    "totalpages = doc_helper.getNumPages()\n",
    "for eachpage in range(totalpages):\n",
    "   p = doc_helper.getPage(eachpage)\n",
    "   indpagetext = p.extractText()\n",
    "   finaltext += indpagetext\n",
    "\n",
    "clean_text = finaltext.replace(\"  \", \" \").replace(\"\\n\", \"; \").replace(';',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"What is the answer to the following question regarding the PDF document?\\n\\n{finaltext}\\n\\n\" \n",
    "q = \"Can you give me a summary of the document?\"\n",
    "\n",
    "try:\n",
    "    final_prompt = prompt + q\n",
    "    messages = [{\"role\": \"system\", \"content\": \"You are a helpful assistant.\"}, {\"role\": \"user\", \"content\": final_prompt}]\n",
    "    response = openai.ChatCompletion.create(engine=model, messages=messages, max_tokens=50)\n",
    "    answer = response.choices[0].text.strip()\n",
    "    print(f\"{q}\\n{answer}\\n\")\n",
    "\n",
    "except InvalidRequestError as e:\n",
    "    print(e.error)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como verás arriba, recibirás un mensaje de error después de ejecutar el fragmento de código anterior. El modelo alcanza su longitud de contexto máxima. Para los modelos GPT-3, el límite de tokens es de 4097 tokens. ¿Cómo solucionamos este problema al proporcionarle todo el contexto necesario, pero sin encontrarnos con el problema del límite de tokens?\n",
    "\n",
    "Para resolver este problema, podemos echar un vistazo a un concepto llamado Chunking."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Chunking\n",
    "\n",
    "El chunking ayuda a limitar la cantidad de información que pasamos al modelo. La información que pasaremos son los trozos más relevantes de los datos en general. Hay muchas consideraciones que entran en juego al hacer chunking. Por ejemplo, necesitas averiguar el mejor tamaño de chunk. Si los trozos son demasiado pequeños, puedes perder contexto importante. Si los trozos son demasiado grandes, pueden contener información innecesaria.\n",
    "\n",
    "A continuación se presentan algunas técnicas comunes de chunking.\n",
    "\n",
    "1. Chunking con trozos más pequeños\n",
    "2. Chunking dividiendo las oraciones\n",
    "3. Chunking con superposición de oraciones\n",
    "4. Chunking de forma recursiva\n",
    "\n",
    "Veamos estas técnicas en acción."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Chunking con trozos más pequeños\n",
    "\n",
    "#### Tarea del Estudiante #4:\n",
    "\n",
    "Agrega código en la celda siguiente. Utiliza la función split() para dividir el texto en trozos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "text = \"The sun was setting over the horizon, casting a warm glow over the landscape. Birds chirped in the trees, and a gentle breeze rustled the leaves. In the distance, a herd of deer grazed in a meadow. The air was filled with the sweet scent of blooming flowers. It was a peaceful and serene scene, perfect for a quiet evening stroll.\"\n",
    "\n",
    "# Add you code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Qué puedes observar sobre los trozos devueltos? ¿Si cada trozo estuviera por sí mismo, podrías entender el significado semántico?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2: Chunking dividiendo las oraciones\n",
    "\n",
    "#### Tarea del Estudiante #5:\n",
    "\n",
    "Agrega código en la celda siguiente. Utiliza la biblioteca spacy y específicamente la función sents para dividir el texto en trozos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Today was a fun day. I had lots of ice cream. I also met my best friend Sally and we played together at the new playground.\"\n",
    "\n",
    "# Add you code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Los resultados son mejores que el método en 4.1? La biblioteca spaCy ayuda a dividir el texto en oraciones individuales. Esto puede ser útil cuando intentas hacer resúmenes de texto. Puedes clasificar las oraciones individuales y usar los mejores resultados en el resumen."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3: Chunking con superposición de oraciones\n",
    "\n",
    "#### Tarea del Estudiante #6:\n",
    "\n",
    "Ejecuta el código a continuación para ver otro ejemplo de chunking. Como verás, el significado semántico se mantiene. En otras palabras, se conserva el contexto entre las oraciones. Esto es especialmente importante cuando estás buscando datos para obtener resultados relevantes o cuando estás resumiendo un fragmento de texto. Es importante capturar las relaciones entre las oraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"The sun was setting over the horizon, casting a warm glow over the landscape. Birds chirped in the trees, and a gentle breeze rustled the leaves. In the distance, a herd of deer grazed in a meadow. The air was filled with the sweet scent of blooming flowers. It was a peaceful and serene scene, perfect for a quiet evening stroll.\"\n",
    "doc = nlp(text)\n",
    "\n",
    "sentences = list(doc.sents)\n",
    "overlap = 1\n",
    "chunks =[]\n",
    "\n",
    "for i in range(len(sentences) - overlap):\n",
    "    chunk = sentences[i : i + overlap + 1]\n",
    "    chunks.append(chunk)\n",
    "\n",
    "for chunk in chunks:\n",
    "    print([sent.text for sent in chunk])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4: Chunking de forma recursiva usando LangChain\n",
    "\n",
    "#### Tarea del Estudiante #7:\n",
    "\n",
    "Agrega los parámetros requeridos para RecursiveCharacterSplitter en la celda siguiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_text = RecursiveCharacterTextSplitter(\n",
    "   # Add parameters here \n",
    ")\n",
    "docs = split_text.create_documents([clean_text])\n",
    "docs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Arriba, realizamos algunos fragmentos utilizando Langchain, un marco popular para crear aplicaciones utilizando modelos de lenguaje grandes. En los métodos anteriores, viste varios ejemplos de chunking. Langchain puede ayudar a hacer que el proceso de chunking sea más fácil con algunos de sus métodos. Estos métodos incluyen fragmentos de tamaño fijo, así como fragmentación recursiva, que acabamos de ver.\n",
    "\n",
    "Por ejemplo, existe CharacterTextSplitter que dividirá el texto dado en un fragmento de tamaño fijo de un tamaño dado y un solapamiento de caracteres dado.\n",
    "\n",
    "RecursiveCharacterTextSplitter divide el texto en fragmentos más pequeños de manera iterativa. Nuevamente, puedes proporcionar el tamaño del fragmento y el recuento de solapamiento del fragmento."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El chunking es una técnica importante por muchas razones. Ayuda a evitar el límite de tokens cuando se trabaja con grandes cantidades de datos y también optimiza la respuesta que recibimos del modelo. Encontrar la técnica de fragmentación adecuada y el tamaño de fragmento es crucial para recibir respuestas relevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criterios de Éxito\n",
    "\n",
    "Para completar este desafío con éxito:\n",
    "\n",
    "* Mostrar comprensión de los tokens y cómo calcularlos.\n",
    "* Demostrar comprensión del chunking experimentando con diferentes técnicas.\n",
    "* Ser capaz de entender la importancia de encontrar la solución de chunking adecuada según si se captura o no el significado semántico."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
